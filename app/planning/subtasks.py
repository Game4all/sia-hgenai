from pydantic import BaseModel, ValidationError, Field
from typing import List, Dict, Optional, Any
from ..utils.format import prompt_template, parse_json_response
import json
from ..utils.bedrock import WrapperBedrock, ConverseMessage
import logging


class SubTask(BaseModel):
    nom: str = Field(..., description="Nom de la sous-t√¢che")
    description: str = Field(..., description="Description de la sous-t√¢che")
    args: Optional[Dict[str, Any]] = Field({}, description="Arguments suppl√©mentaires pour la sous-t√¢che")


@prompt_template
def validate_user_request_template(user_request: str, few_shot_examples: Optional[List[Dict[str, Any]]] = None) -> str:
    """
    V√©rifie que la requ√™te utilisateur a pour sujet l'analyse ou l'adaptaion des collectivites francasies face aux  des risques environnementaux. \n
    V√©rifie que le requ√™te utilisateur contient au moins un des risques suivants ou cat√©gories de risques :\n"
    **Risques physiques aigus** :\n"
    - Inondation\n"
    - Feu de for√™t\n"
    - √âv√©nements cycloniques (temp√™tes)\n"
    - Tremblement de terre\n"
    - S√©cheresse\n"
    - Vague de chaleur\n\n"
    **Risques physiques chroniques** :\n"
    - Retrait-gonflement des argiles\n"
    - √ârosion du littoral\n"
    - √âl√©vation du niveau de la mer\n"
    - Perte d‚Äôenneigement\n\n"
    **Risques environnementaux** :\n"
    - Stress hydrique\n"
    - Perte de biodiversit√©\n"
    - Pollution de l‚Äôair, des sols, de l‚Äôeau\n"
    - Gestion des d√©chets\n\n"

    De plus, assure-toi qu'un lieu en France est mentionn√©. Indique √©galement son niveau administratif (commune, d√©partement, r√©gion, groupement de communes, etc.).\n"
    Si les deux crit√®res sont remplis, corrige l'orthographe et la grammaire si n√©cessaire et trouve les mots-cl√©s pertinents en plus, comme par exemple la p√©riode de temps, le type de lieu (h√¥pital, √©cole, etc.) \n"
    Si un crit√®re manque, indique pr√©cis√©ment ce qui est absent et donne un exemple de requ√™te valide bas√©e sur le prompt. \n"
    Retourne un JSON sous la forme suivante si la requ√™te est valide : \n"

    {\n"
        "requete_valide": true,\n"
        "message": "<requ√™te reformul√©e>",\n"
        "risques": ["<risque1 ou cat√©gorie1>", "<risque2 ou cat√©gorie2>", ...],\n"
        "lieux": ["<lieu1>", "<lieu2>"],\n"
        "niv_admin": "<niveau_administratif>",\n"
    }\n"
    Si la requ√™te n'est pas valide, retourne un JSON sous la forme suivante : \n"
    {\n"
        'requete_valide': false,\n"
        'message': '<explication du probl√®me>'\n"
    }\n\n"

    {% if few_shot_examples %}
    Voici quelques exemples de requ√™tes avec leurs r√©sultats de validation : \n
    {% for example in few_shot_examples %}
    Requ√™te utilisateur : {{ example["requete"] }}\n
    R√©sultat :
    {
        "requete_valide": {{ example["requete_valide"] }},
        "message": "{{ example["message"] }}",
        "risques": "{{ example["risques"] }}",
        "lieux": "{{ example["lieux"] }}",
        "niv_admin": "{{ example["niv_admin"] }}"
    }\n
    {% endfor %}
    {% endif %}

    Voici la requ√™te √† traiter : \n
    **Requ√™te utilisateur :** {{ user_request }} \n
    """

    pass


def validate_user_request(user_request: str, client: WrapperBedrock, model_id: str) -> Dict[str, Any]:
    """
    Valide une requ√™te utilisateur pour s'assurer qu'elle contient les informations n√©cessaires.

    :param prompt: Prompt pour guider le mod√®le lors de la correction.
    :param client: Instance de WrapperBedrock pour interagir avec le LLM.
    :param model_id: ID du mod√®le Bedrock √† utiliser.

    :return: Dictionnaire contenant les informations valid√©es ou un message d'erreur.
    """
    few_shot_examples = [
        {
            "requete": "Quels sont les plans d'adaptation de la region Provence-Alpes-C√¥te d'Azur face aux vague de chaleur et ala s√©cheresse ?",
            "requete_valide": "true",
            "message": "Quels sont les plans d'adaptation de la r√©gion Provence-Alpes-C√¥te d'Azur face aux vagues de chaleur et √† la s√©cheresse ?",
            "risques": ["Vague de chaleur", "S√©cheresse"],
            "lieux": ["Provence-Alpes-C√¥te d'Azur"],
            "niv_admin": "r√©gion"
        },
        {
            "requete": "Comment la France g√®re-t-elle le stress hydrique ?",
            "requete_valide": "false",
            "message": "La requ√™te mentionne un risque environnemental (stress hydrique), mais ne pr√©cise pas de localisation en France. Veuillez sp√©cifier un lieu comme une commune, un d√©partement ou une r√©gion. Par exemple : 'Comment la r√©gion Occitanie g√®re-t-elle le stress hydrique ?'"
        },
        {
            "requete": "Quels sont les projets d'urbanisation pr√©vus √† Lyon ?",
            "requete_valide": "false",
            "message": "La requ√™te mentionne un lieu en France (Lyon, commune) mais ne fait r√©f√©rence √† aucun risque environnemental. Veuillez inclure un risque environnemental pertinent. Par exemple : 'Quels sont les projets d'urbanisation pr√©vus √† Lyon pour faire face aux risques d'inondation ?'"
        },
        {
            "requete": "Quelles sont les mesures prises contre les inondtaions √† Paris, Bordeaux et Lyon ?",
            "requete_valide": "true",
            "message": "Quelles sont les mesures prises contre les inondations √† Paris, Bordeaux et Lyon ?",
            "risques": ["Inondation"],
            "lieux": ["Paris", "Bordeaux", "Lyon"],
            "niv_admin": "commune"
        },
        {
            "requete": "Comment la m√©tropole de Lyon s'adapte-t-elle √† la pollution de l'air ?",
            "requete_valide": "true",
            "message": "Comment la m√©tropole de Lyon s'adapte-t-elle √† la pollution de l'air ?",
            "risques": ["Pollution de l‚Äôair"],
            "lieux": ["M√©tropole de Lyon"],
            "niv_admin": "groupement de communes"
        }
    ]
    instruction = validate_user_request_template(user_request=user_request, few_shot_examples=few_shot_examples)
    messages = [ConverseMessage.make_user_message(instruction)]
    response = client.converse(model_id=model_id, messages=messages)
    response_text = response.content[0].text
    print(response_text)
    
    try:
        parsed_response = parse_json_response(response_text)
        if isinstance(parsed_response, dict) and {"requete_valide", "message", "risques", "lieux", "niv_admin"} <= parsed_response.keys():
            return parsed_response
        else:
            raise json.JSONDecodeError
    except Exception as e:
        print(e)
        pass
    
    return {"requete_valide": False, "message": "Oups... Nous n'avons pas pu valider la requ√™te. Veuillez r√©essayer."}


@prompt_template
def subtask_prompt_template(user_request: str, few_shot_examples: Optional[List[Dict[str, Any]]] = None) -> str:
    """
    Vous √™tes un planificateur de t√¢ches avanc√© au sein de SFIL, une banque d'investissement sp√©cialis√©e dans la recherche et l'analyse des documents relatifs √† l'adaptation des collectivit√©s aux risques climatiques. Votre t√¢che consiste √† analyser la requ√™te utilisateur et √† diviser le processus en sous-t√¢ches clairement d√©finies. Ces sous-t√¢ches doivent √™tre organis√©es en fonction de l'ordre d'ex√©cution et des d√©pendances. Elles doivent couvrir les √©tapes suivantes, qui sont g√©n√©riques et peuvent varier l√©g√®rement selon le cas sp√©cifique :

    1. **Recherche** : Identification et collecte des documents et donn√©es pertinentes relatives aux risques climatiques et √† l‚Äôadaptation des collectivit√©s.
    2. **Analyse** : Analyse des documents pour comprendre l'impact des risques climatiques sur les collectivit√©s et √©valuer les mesures d‚Äôadaptation existantes.
    3. **Visualisation** : Cr√©ation de visualisations (graphiques, cartes, etc.) permettant de mieux comprendre et communiquer les r√©sultats de l‚Äôanalyse.
    4. **Synth√®se** : √âlaboration d‚Äôun rapport d√©taill√©, r√©sumant les r√©sultats de l‚Äôanalyse et proposant des recommandations adapt√©es pour les collectivit√©s.

    Chaque sous-t√¢che doit inclure :
    - Une **description claire** et pr√©cise de l‚Äô√©tape √† r√©aliser.
    - Un **ordre d'ex√©cution** d√©finissant dans quel ordre les sous-t√¢ches doivent √™tre r√©alis√©es.
    - Une **liste de d√©pendances** (si applicable) sp√©cifiant les sous-t√¢ches dont celle-ci d√©pend avant de pouvoir √™tre ex√©cut√©e.

    La structure du format JSON pour chaque sous-t√¢che est la suivante :
    {
        "nom": "<nom de la sous-t√¢che>",
        "description": "<description de la sous-t√¢che>",
        "args": {
            "<argument1>": "<valeur1>",
            "<argument2>": "<valeur2>",
            ...
        }
    }

    {% if few_shot_examples %}
    Voici quelques exemples de t√¢ches correctement divis√©es :

    {% for example in few_shot_examples %}
    ---
    **Requ√™te:** {{ example['request'] }}
    **Sous-t√¢ches g√©n√©r√©es :**
    {% for subtask in example['subtasks'] %}
    - **id :** {{ subtask['id'] }}
    - **description :** {{ subtask['description'] }}
    - **dependencies :** {{ subtask.get('dependencies', []) }}
    - **order :** {{ subtask['order'] }}
    {% endfor %}
    {% endfor %}
    ---
    {% endif %}

    Voici la requ√™te √† traiter : \n

    **Requ√™te utilisateur :**
    {{ user_request["message"] }} \n

    Retournez UNIQUEMENT un JSON contenant la liste des sous-t√¢ches sans autre texte.
    """
    pass


def divide_task(prompt: str,
            client: WrapperBedrock,
            model_id: str,
            max_retries: int) -> Optional[List[SubTask]]:
    """
    Logique pour valider les sous-t√¢ches g√©n√©r√©es par le mod√®le Bedrock.
    Si une erreur est d√©tect√©e, guide le mod√®le pour qu'il se corrige et relance la demande.

    :param prompt: Prompt pour guider le mod√®le lors de la correction.
    :param client: Instance de WrapperBedrock pour interagir avec le LLM.
    :param model_id: ID du mod√®le Bedrock √† utiliser.
    :param max_retries: Nombre maximum

    :return: Liste de sous-t√¢ches valid√©es ou une la t√†che initiale si l'√©chec persiste.
    """
    attempt = 0
    messages = [ConverseMessage.make_system_message(prompt)]
    while attempt < max_retries:
        try:
            # TODO : fix subtasks parsing it doesn't return a list of SubTask but only a string subtasks
            llm_response = client.converse(model_id, messages=messages)
            subtasks_data = parse_json_response(llm_response.content[0].text)
            validated_subtasks = [SubTask(**task) for task in subtasks_data]
            return validated_subtasks
        except (ValidationError, json.JSONDecodeError) as e:
            if attempt < max_retries:
                attempt += 1
                logging.error(f"‚ùå Erreur lors de la validation des sous-t√¢ches (Tentative {attempt}/{max_retries}): {e}")
                response = ConverseMessage.make_assistant_message("‚ö†Ô∏è Erreur d√©tect√©e. Reformulez la r√©ponse au format JSON valide.")
                messages.append(response)
                instruction = (
                    "\n\n‚ö†Ô∏è Erreur d√©tect√©e. Reformulez la r√©ponse au format JSON valide :\n"
                    "- Chaque sous-t√¢che doit inclure `id`, `description`, `dependencies` et `order`.\n"
                    "- Corrigez toute erreur de formatage et r√©essayez.\n"
                )
                messages.append(ConverseMessage.make_system_message(instruction))
            else:
                logging.critical("üí• √âchec apr√®s plusieurs tentatives. Impossible de diviser la t√¢che.")
                raise e


def get_subtasks(
    client: WrapperBedrock,
    validation_model_id: str,
    planning_model_id: str,
    user_request: str,
    few_shot_examples: Optional[List[Dict[str, Any]]] = None,
    max_retries: int = 3,
) -> List[SubTask]:
    """
    Divise une t√¢che utilisateur en sous-t√¢ches coh√©rentes en utilisant WrapperBedrock.
    Si une erreur est d√©tect√©e, guide le mod√®le pour qu'il se corrige et relance la demande.

    :param client: Instance de WrapperBedrock pour interagir avec le LLM.
    :param validation_model_id: ID du mod√®le Bedrock pour la validation de la requ√™te utilisateur.
    :param planning_model_id: ID du mod√®le Bedrock pour la division de la t√¢che en sous-t√¢ches.
    :param user_request: Requ√™te utilisateur √† diviser en sous-t√¢ches.
    :param few_shot_examples: Exemples pour le Few-Shot Prompting (optionnel).
    :param max_retries: Nombre maximum de tentatives en cas d'erreur.
    :param kwargs: Arguments suppl√©mentaires √† transmettre au mod√®le.

    :return: Liste de sous-t√¢ches valid√©es ou une la t√†che initiale si l'√©chec persiste.
    """
    # V√©rification de la requ√™te utilisateur
    output = validate_user_request(user_request, client, validation_model_id)
    if not output['requete_valide']:
        return client.converse(model_id=validation_model_id, messages=[ConverseMessage.make_user_message(output['message'])])
        
    # G√©n√©ration du prompt initial
    subtask_prompt = subtask_prompt_template(user_request=output, few_shot_examples=few_shot_examples)

    # Validation de la r√©ponse
    subtasks = divide_task(subtask_prompt, client, planning_model_id, max_retries)

    return subtasks